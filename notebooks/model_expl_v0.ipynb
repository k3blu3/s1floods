{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood model exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import rasterio\n",
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/k3blu3/datasets/s1floods'\n",
    "meta_file = 'flood-training-metadata.csv'\n",
    "image_dir = os.path.join(root_dir, 'train_features')\n",
    "label_dir = os.path.join(root_dir, 'train_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(root_dir, meta_file))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop_duplicates(subset=['chip_id'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for each extension data type with path to full image\n",
    "extensions = ['vv', 'vh', 'nasadem', 'jrc-gsw-occurrence']\n",
    "ext_paths = dict()\n",
    "label_paths = list()\n",
    "for ext in extensions:\n",
    "    ext_paths[ext] = list()\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    for ext in extensions:\n",
    "        fname = os.path.join(image_dir, f\"{row['chip_id']}_{ext}.tif\")\n",
    "        ext_paths[ext].append(fname)\n",
    "        \n",
    "    fname = os.path.join(label_dir, f\"{row['chip_id']}.tif\")\n",
    "    label_paths.append(fname)\n",
    "        \n",
    "for ext in extensions:\n",
    "    df[ext] = ext_paths[ext]\n",
    "    \n",
    "df['label'] = label_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample three floods for validation set\n",
    "flood_ids = df.flood_id.unique().tolist()\n",
    "val_flood_ids = random.sample(flood_ids, 3)\n",
    "val_flood_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df.flood_id.isin(val_flood_ids)]\n",
    "df_train = df[~df.flood_id.isin(val_flood_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = df_val[['chip_id'] + extensions]\n",
    "val_y = df_val['label']\n",
    "\n",
    "train_x = df_train[['chip_id'] + extensions]\n",
    "train_y = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reset_index(drop=True)\n",
    "train_y = train_y.reset_index(drop=True)\n",
    "val_x = val_x.reset_index(drop=True)\n",
    "val_y = val_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to rescale an input image with percentile scaling\n",
    "def rescale_img(img, min_val=0.0, max_val=1.0, dtype=np.float32, pmin=0.0, pmax=100.0, vmin=None, vmax=None):\n",
    "    # compute min and max percentile ranges to scale with\n",
    "    if not vmin:\n",
    "        vmin, vmax = np.nanpercentile(img, pmin), np.nanpercentile(img, pmax)\n",
    "    \n",
    "    img_rescale = ((img - vmin) * (1.0 / (vmax - vmin) * max_val)).astype(dtype)\n",
    "    np.ma.clip(img_rescale, min_val, max_val, out=img_rescale)\n",
    "    \n",
    "    img_rescale = np.nan_to_num(img_rescale)\n",
    "\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ['vv', 'vh', 'nasadem', 'jrc-gsw-occurrence']\n",
    "norms = [(-50, 0), (-50, 0), (0, 500), (0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xforms = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.RandomRotate90(),\n",
    "        albumentations.HorizontalFlip(),\n",
    "        albumentations.VerticalFlip()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y=None, xforms=None):\n",
    "        self.data = x\n",
    "        self.label = y\n",
    "        self.xforms = xforms\n",
    "        self.extensions = extensions\n",
    "        self.norms = norms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __read_image(self, img):\n",
    "        data_stack = list()\n",
    "        for idx, (ext, norm) in enumerate(zip(self.extensions, self.norms)):\n",
    "            # read as masked array\n",
    "            with rasterio.open(img[ext]) as src:\n",
    "                data = src.read(1, masked=True)\n",
    "            \n",
    "            # normalize this layer\n",
    "            data = rescale_img(data, vmin=norm[0], vmax=norm[1]).filled(0)\n",
    "            \n",
    "            # append to stack\n",
    "            data_stack.append(data)\n",
    "        \n",
    "        # throw data into stack\n",
    "        data_stack = np.stack(data_stack, axis=-1)\n",
    "        return data_stack\n",
    "    \n",
    "    def __read_label(self, label):\n",
    "        with rasterio.open(label) as src:\n",
    "            data = src.read(1)\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # grab image from dataframe\n",
    "        self.augment = random.uniform(0, 1)\n",
    "        \n",
    "        img = self.data.loc[idx]\n",
    "        \n",
    "        # read in image layers, normalize each layer\n",
    "        image = self.__read_image(img)\n",
    "        \n",
    "        # load label (during training)\n",
    "        if self.label is not None:\n",
    "            lbl = self.label.loc[idx]\n",
    "            label = self.__read_label(lbl)\n",
    "            \n",
    "            if xforms is not None:\n",
    "                aug = self.xforms(image=image, mask=label)\n",
    "                \n",
    "            image = np.transpose(aug['image'], axes=(2, 0, 1))\n",
    "            label = aug['mask']\n",
    "            \n",
    "            sample = {\n",
    "                'chip_id': img.chip_id,\n",
    "                'image': image,\n",
    "                'target': label\n",
    "            }\n",
    "            \n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the data looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "ds = FloodDataset(train_x, train_y, xforms)\n",
    "sample = ds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "plt.tight_layout()\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(sample['image'][0, :, :])\n",
    "\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(sample['image'][1, :, :])\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.axis('off')\n",
    "plt.imshow(sample['image'][2, :, :])\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.axis('off')\n",
    "plt.imshow(sample['image'][3, :, :])\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.axis('off')\n",
    "label = sample['target']\n",
    "label[label==255] = 0\n",
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XEDiceLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Computes (0.5 * CrossEntropyLoss) + (0.5 * DiceLoss).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.xe = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        valid_pixel_mask = true.ne(255)  # valid pixel mask\n",
    "\n",
    "        # Cross-entropy loss\n",
    "        temp_true = torch.where((true == 255), 0, true)  # cast 255 to 0 temporarily\n",
    "        xe_loss = self.xe(pred, temp_true)\n",
    "        xe_loss = xe_loss.masked_select(valid_pixel_mask).mean()\n",
    "\n",
    "        # Dice loss\n",
    "        pred = torch.softmax(pred, dim=1)[:, 1]\n",
    "        pred = pred.masked_select(valid_pixel_mask)\n",
    "        true = true.masked_select(valid_pixel_mask)\n",
    "        dice_loss = 1 - (2.0 * torch.sum(pred * true)) / (torch.sum(pred + true) + 1e-7)\n",
    "\n",
    "        return (0.5 * xe_loss) + (0.5 * dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_and_union(pred, true):\n",
    "    \"\"\"\n",
    "    Calculates intersection and union for a batch of images.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): a tensor of predictions\n",
    "        true (torc.Tensor): a tensor of labels\n",
    "\n",
    "    Returns:\n",
    "        intersection (int): total intersection of pixels\n",
    "        union (int): total union of pixels\n",
    "    \"\"\"\n",
    "    valid_pixel_mask = true.ne(255)  # valid pixel mask\n",
    "    true = true.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "    pred = pred.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "\n",
    "    # Intersection and union totals\n",
    "    intersection = np.logical_and(true, pred)\n",
    "    union = np.logical_or(true, pred)\n",
    "    return intersection.sum(), union.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodModel(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(FloodModel, self).__init__()\n",
    "        self.hparams.update(hparams)\n",
    "        self.save_hyperparameters()\n",
    "        self.backbone = self.hparams.get(\"backbone\", \"resnet34\")\n",
    "        self.weights = self.hparams.get(\"weights\", \"imagenet\")\n",
    "        self.learning_rate = self.hparams.get(\"lr\", 1e-3)\n",
    "        self.max_epochs = self.hparams.get(\"max_epochs\", 1000)\n",
    "        self.min_epochs = self.hparams.get(\"min_epochs\", 6)\n",
    "        self.patience = self.hparams.get(\"patience\", 4)\n",
    "        self.num_workers = self.hparams.get(\"num_workers\", 2)\n",
    "        self.batch_size = self.hparams.get(\"batch_size\", 32)\n",
    "        self.x_train = self.hparams.get(\"x_train\")\n",
    "        self.y_train = self.hparams.get(\"y_train\")\n",
    "        self.x_val = self.hparams.get(\"x_val\")\n",
    "        self.y_val = self.hparams.get(\"y_val\")\n",
    "        self.output_path = self.hparams.get(\"output_path\", \"model-outputs\")\n",
    "        self.gpu = self.hparams.get(\"gpu\", False)\n",
    "        self.xforms = self.hparams.get(\"xforms\", None)\n",
    "\n",
    "        # Where final model will be saved\n",
    "        self.output_path = Path.cwd() / self.output_path\n",
    "        self.output_path.mkdir(exist_ok=True)\n",
    "\n",
    "        # Track validation IOU globally (reset each epoch)\n",
    "        self.intersection = 0\n",
    "        self.union = 0\n",
    "\n",
    "        # Instantiate datasets, model, and trainer params\n",
    "        self.train_dataset = FloodDataset(\n",
    "            self.x_train, self.y_train, xforms=self.xforms\n",
    "        )\n",
    "        self.val_dataset = FloodDataset(self.x_val, self.y_val, xforms=None)\n",
    "        self.model = self._prepare_model()\n",
    "        self.trainer_params = self._get_trainer_params()\n",
    "\n",
    "    ## Required LightningModule methods ##\n",
    "\n",
    "    def forward(self, image):\n",
    "        # Forward pass\n",
    "        return self.model(image)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Switch on training mode\n",
    "        self.model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        # Calculate training loss\n",
    "        criterion = XEDiceLoss()\n",
    "        xe_dice_loss = criterion(preds, y)\n",
    "\n",
    "        # Log batch xe_dice_loss\n",
    "        self.log(\n",
    "            \"xe_dice_loss\",\n",
    "            xe_dice_loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return xe_dice_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Switch on validation mode\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass & softmax\n",
    "        preds = self.forward(x)\n",
    "        preds = torch.softmax(preds, dim=1)[:, 1]\n",
    "        preds = (preds > 0.5) * 1\n",
    "\n",
    "        # Calculate validation IOU (global)\n",
    "        intersection, union = intersection_and_union(preds, y)\n",
    "        self.intersection += intersection\n",
    "        self.union += union\n",
    "\n",
    "        # Log batch IOU\n",
    "        batch_iou = intersection / union\n",
    "        self.log(\n",
    "            \"iou\", batch_iou, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return batch_iou\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # DataLoader class for training\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # DataLoader class for validation\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Define scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"max\", factor=0.5, patience=self.patience\n",
    "        )\n",
    "        scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }  # logged value to monitor\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # Calculate IOU at end of epoch\n",
    "        epoch_iou = self.intersection / self.union\n",
    "\n",
    "        # Reset metrics before next epoch\n",
    "        self.intersection = 0\n",
    "        self.union = 0\n",
    "\n",
    "        # Log epoch validation IOU\n",
    "        self.log(\"val_loss\", epoch_iou, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return epoch_iou\n",
    "\n",
    "    ## Convenience Methods ##\n",
    "\n",
    "    def _prepare_model(self):\n",
    "        unet_model = smp.Unet(\n",
    "            encoder_name=self.backbone,\n",
    "            encoder_weights=self.weights,\n",
    "            in_channels=4,\n",
    "            classes=2,\n",
    "        )\n",
    "        if self.gpu:\n",
    "            unet_model.cuda()\n",
    "        return unet_model\n",
    "\n",
    "    def _get_trainer_params(self):\n",
    "        # Define callback behavior\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=self.output_path,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"max\",\n",
    "            verbose=True,\n",
    "        )\n",
    "        early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=(self.patience * 3),\n",
    "            mode=\"max\",\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Specify where TensorBoard logs will be saved\n",
    "        self.log_path = Path.cwd() / self.hparams.get(\"log_path\", \"tensorboard-logs\")\n",
    "        self.log_path.mkdir(exist_ok=True)\n",
    "        logger = pl.loggers.TensorBoardLogger(self.log_path, name=\"benchmark-model\")\n",
    "\n",
    "        trainer_params = {\n",
    "            \"callbacks\": [checkpoint_callback, early_stop_callback],\n",
    "            \"max_epochs\": self.max_epochs,\n",
    "            \"min_epochs\": self.min_epochs,\n",
    "            \"default_root_dir\": self.output_path,\n",
    "            \"logger\": logger,\n",
    "            \"gpus\": None if not self.gpu else 1,\n",
    "            \"fast_dev_run\": self.hparams.get(\"fast_dev_run\", False),\n",
    "            \"num_sanity_val_steps\": self.hparams.get(\"val_sanity_checks\", 0),\n",
    "        }\n",
    "        return trainer_params\n",
    "\n",
    "    def fit(self):\n",
    "        # Set up and fit Trainer object\n",
    "        self.trainer = pl.Trainer(**self.trainer_params)\n",
    "        self.trainer.fit(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    # Required hparams\n",
    "    \"x_train\": train_x,\n",
    "    \"x_val\": val_x,\n",
    "    \"y_train\": train_y,\n",
    "    \"y_val\": val_y,\n",
    "    # Optional hparams\n",
    "    \"backbone\": \"resnet34\",\n",
    "    \"weights\": \"imagenet\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"min_epochs\": 6,\n",
    "    \"max_epochs\": 1000,\n",
    "    \"patience\": 4,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 6,\n",
    "    \"val_sanity_checks\": 0,\n",
    "    \"fast_dev_run\": False,\n",
    "    \"output_path\": \"model-outputs\",\n",
    "    \"log_path\": \"tensorboard_logs\",\n",
    "    \"gpu\": torch.cuda.is_available(),\n",
    "    \"xforms\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_model = FloodModel(hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "mldev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
